{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing necessary Libraries \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL \n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data='E:/data science work/data/face mask dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing tenserflow libraries for making deeplearning Model\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Activation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just trying something else methods for taking the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label={0:'mask',1:'no mask'}\n",
    "# face_classifier=cv.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=[]\n",
    "# target=[]\n",
    "# for folder in os.listdir('face mask dataset'):\n",
    "#     for i in os.listdir('face mask dataset/{}'.format(folder)):\n",
    "#         image=cv.imread('face mask dataset/{}/{}'.format(folder,i))\n",
    "#         gray=cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n",
    "#         faces=face_classifier.detectMultiScale(gray,1.2,5)\n",
    "#         if (faces!=()):\n",
    "#             for a,b,c,d in faces:\n",
    "#                 crop=gray[b:b+d,a:a+c]\n",
    "#                 if crop!=():\n",
    "#                     resized=cv.resize(crop,(224,224))\n",
    "#                     data.append(resized)\n",
    "#                     target.append(folder)\n",
    "#         else:\n",
    "#             continue\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upto this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255,horizontal_flip=True,shear_range=.2,zoom_range=.2)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1376 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(data,target_size=(224,224),class_mode='categorical',shuffle=True,batch_size=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with mask': 0, 'without mask': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the dim array RGB\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=3,input_shape=(224,224,3),activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## the 1dim array GRAY\n",
    "# model=Sequential()\n",
    "# model.add(Conv2D(32,kernel_size=3,input_shape=(224,224,1),activation='relu'))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# model.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "# model.add(MaxPooling2D(2,2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1,activation='sigmoid'))\n",
    "# model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep model\n",
    "# model=Sequential()\n",
    "\n",
    "# model.add(Conv2D(200,(3,3),input_shape=(224,224,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# #The first CNN layer followed by Relu and MaxPooling layers\n",
    "\n",
    "# model.add(Conv2D(100,(3,3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# #The second convolution layer followed by Relu and MaxPooling layers\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# #Flatten layer to stack the output convolutions from second convolution layer\n",
    "# model.add(Dense(50,activation='relu'))\n",
    "# #Dense layer of 64 neurons\n",
    "# model.add(Dense(2,activation='softmax'))\n",
    "# #The Final layer with two outputs for two categories\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#transfer learning\n",
    "vgg=VGG16(input_shape=(224,224,3),weights='imagenet',include_top=False)\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable=False\n",
    "x=Flatten()(vgg.output)\n",
    "x=Dense(50,activation='relu')(x)\n",
    "final=Dense(2,activation='softmax')(x)\n",
    "model1=Model(inputs=vgg.input,outputs=final)\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non generator data\n",
    "# model.fit(array,target,epochs=10,batch_size=20,validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ajay\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "56/56 [==============================] - 842s 15s/step - loss: 0.6073 - acc: 0.8428\n",
      "Epoch 2/3\n",
      "56/56 [==============================] - 835s 15s/step - loss: 0.0510 - acc: 0.9914\n",
      "Epoch 3/3\n",
      "56/56 [==============================] - 19524s 349s/step - loss: 0.0337 - acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2257ab1a8d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(train_generator,epochs=10,steps_per_epoch=len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=model1.predict_generator(train_generator,steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label={0:'mask',1:'no mask'}\n",
    "face_classifier=cv.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def detects(frame):\n",
    "    gray=cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.2)\n",
    "    for a,b,c,d in faces:\n",
    "        crop=frame[b:b+d,a:a+c]\n",
    "        resized=cv.resize(crop,(224,224))\n",
    "        resized=resized/255.0\n",
    "        resized=np.expand_dims(resized,axis=0)\n",
    "        pred=model1.predict(resized)\n",
    "        prediction=np.argmax(pred,axis=1)[0]\n",
    "        pct=str(int(np.max(pred,axis=1)[0]*100))\n",
    "        if prediction==0:\n",
    "            cv.rectangle(frame,(a,b),(a+c,b+d),(0,255,0),3)\n",
    "            cv.putText(frame,label[0]+pct+'%',(a,b-10),cv.FONT_HERSHEY_SIMPLEX,.8,(0,255,0),2)\n",
    "        else:\n",
    "            cv.rectangle(frame,(a,b),(a+c,b+d),(0,0,255),3)\n",
    "            cv.putText(frame,label[1]+pct+'%',(a,b-10),cv.FONT_HERSHEY_SIMPLEX,.8,(0,0,255),2)\n",
    "    return frame\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=cv.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame=c.read()\n",
    "    cv.imshow('live mask prediction',detects(frame))\n",
    "    if cv.waitKey(1)==13:\n",
    "        break\n",
    "c.release()\n",
    "cv.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hosting the appte server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from flask import Flask,render_template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE.HTML\n",
    "# <html lang=\"en\">\n",
    "\n",
    "# <head>\n",
    "#     <meta charset=\"UTF-8\">\n",
    "#     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "#     <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n",
    "#     <title>AI Demo</title>\n",
    "#     <link href=\"https://cdn.bootcss.com/bootstrap/4.0.0/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "#     <script src=\"https://cdn.bootcss.com/popper.js/1.12.9/umd/popper.min.js\"></script>\n",
    "#     <script src=\"https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js\"></script>\n",
    "#     <script src=\"https://cdn.bootcss.com/bootstrap/4.0.0/js/bootstrap.min.js\"></script>\n",
    "#     <link href=\"{{ url_for('static', filename='css/main.css') }}\" rel=\"stylesheet\">      \n",
    "# </head>\n",
    "\n",
    "# <body>\n",
    "#     <nav class=\"navbar navbar-dark bg-dark\">\n",
    "#         <div class=\"container\">\n",
    "#             <a class=\"navbar-brand\" href='{{url_for('pre')}}'>AI Demo</a>\n",
    "#             <button class=\"btn btn-outline-secondary my-2 my-sm-0\" type=\"submit\">Help</button>\n",
    "#         </div>\n",
    "#     </nav>\n",
    "#     <div class=\"container\">\n",
    "# <a href='{{url_for('pre')}}'> start face detection</a>\n",
    "#         <div id=\"content\" style=\"margin-top:2em\">{% block content %}{% endblock %}</div>\n",
    "#     </div>\n",
    "\n",
    "\n",
    "# </body>\n",
    "\n",
    "# </html>\n",
    "#  INDEX.HTML\n",
    "# {% extends \"base.html\" %} {% block content %}\n",
    "\n",
    "# <h2>Image Classifier</h2>\n",
    "\n",
    "# <div>\n",
    "#     <form id=\"upload-file\" method=\"post\" enctype=\"multipart/form-data\">\n",
    "#         <label for=\"imageUpload\" class=\"upload-label\">\n",
    "#             Choose...\n",
    "#         </label>\n",
    "#         <input type=\"file\" name=\"file\" id=\"imageUpload\" accept=\".png, .jpg, .jpeg\">\n",
    "#     </form>\n",
    "\n",
    "#     <div class=\"image-section\" style=\"display:none;\">\n",
    "#         <div class=\"img-preview\">\n",
    "#             <div id=\"imagePreview\">\n",
    "#             </div>\n",
    "#         </div>\n",
    "#         <div>\n",
    "#             <button type=\"button\" class=\"btn btn-primary btn-lg \" id=\"btn-predict\">Predict!</button>\n",
    "#         </div>\n",
    "#     </div>\n",
    "\n",
    "#     <div class=\"loader\" style=\"display:none;\"></div>\n",
    "\n",
    "#     <h3 id=\"result\">\n",
    "#         <span> </span>\n",
    "#     </h3>\n",
    "\n",
    "# </div>\n",
    "\n",
    "# {% endblock %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [03/Oct/2020 03:40:27] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [03/Oct/2020 03:40:46] \"\u001b[37mGET /prediction HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "def detect1(frame):\n",
    "    gray=cv.cvtColor(frame,cv.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.2)\n",
    "    for a,b,c,d in faces:\n",
    "        crop=frame[b:b+d,a:a+c]\n",
    "        resized=cv.resize(crop,(224,224))\n",
    "        resized=resized/255.0\n",
    "        resized=np.expand_dims(resized,axis=0)\n",
    "        pred=model1.predict(resized)\n",
    "        prediction=np.argmax(pred,axis=1)[0]\n",
    "        pct=str(int(np.max(pred,axis=1)[0]*100))\n",
    "        if prediction==0:\n",
    "            cv.rectangle(frame,(a,b),(a+c,b+d),(0,255,0),3)\n",
    "            cv.putText(frame,label[0]+pct+'%',(a,b-10),cv.FONT_HERSHEY_SIMPLEX,.8,(0,255,0),2)\n",
    "        else:\n",
    "            cv.rectangle(frame,(a,b),(a+c,b+d),(0,0,255),3)\n",
    "            cv.putText(frame,label[1]+pct+'%',(a,b-10),cv.FONT_HERSHEY_SIMPLEX,.8,(0,0,255),2)\n",
    "    return frame\n",
    "            \n",
    "app=Flask(__name__,template_folder='template')\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('base.html')\n",
    "@app.route('/prediction',methods=['POST','GET'])\n",
    "def pre():\n",
    "    c=cv.VideoCapture(0)\n",
    "    while True:\n",
    "        ret,frame=c.read()\n",
    "        cv.imshow('live mask prediction',detect1(frame))\n",
    "        if cv.waitKey(1)==13:\n",
    "            break        \n",
    "    c.release()\n",
    "    cv.destroyAllWindows()\n",
    "    return render_template('index.html')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
